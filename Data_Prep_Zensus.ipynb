{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6886dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 2)) (2.3.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 3)) (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tomsa\\appdata\\roaming\\python\\python313\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn->-r requirements.txt (line 3)) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tomsa\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tomsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tomsa\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bad38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "support_data_path = \"./Datasets/Support Datasets/\"\n",
    "ars_data_path = \"./Datasets/Statistikportal DE/\"\n",
    "zensus_data_path = \"./Datasets/Zensus/\"\n",
    "zensus_csv_data_path = \"./Datasets/Zensus/csv_sheets_export/\"\n",
    "\n",
    "df = pd.read_excel(f\"{ars_data_path}Anschriften_Regionalschluessel.xlsx\", engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7eca2",
   "metadata": {},
   "source": [
    "### Regionalschlüssel auslesen ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c533aa2",
   "metadata": {},
   "source": [
    "Es werden nur noch benötigte Spalten behalten und die Spaltenköpfe werden bennant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb428a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RS = df.iloc[:, [1, 4, 5, 6, 7, 10, 11]]\n",
    "df_RS.columns = ['Land', 'Textkennzeichen', 'ARS', 'Amtlicher Gemeindeschlüssel(AGS)', 'Gemeinde/Stadt', 'PLZ', 'Ort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8def1b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Land</th>\n",
       "      <th>Textkennzeichen</th>\n",
       "      <th>ARS</th>\n",
       "      <th>Amtlicher Gemeindeschlüssel(AGS)</th>\n",
       "      <th>Gemeinde/Stadt</th>\n",
       "      <th>PLZ</th>\n",
       "      <th>Ort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>24105</td>\n",
       "      <td>Kiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>Kreisfreie Stadt</td>\n",
       "      <td>01001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flensburg, Stadt</td>\n",
       "      <td>24931</td>\n",
       "      <td>Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>Kreisfreie Stadt</td>\n",
       "      <td>010010000000</td>\n",
       "      <td>01001000</td>\n",
       "      <td>Flensburg, Stadt</td>\n",
       "      <td>24937</td>\n",
       "      <td>Flensburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>Kreisfreie Stadt</td>\n",
       "      <td>01002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kiel, Landeshauptstadt</td>\n",
       "      <td>24103</td>\n",
       "      <td>Kiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>Kreisfreie Stadt</td>\n",
       "      <td>010020000000</td>\n",
       "      <td>01002000</td>\n",
       "      <td>Kiel, Landeshauptstadt</td>\n",
       "      <td>24103</td>\n",
       "      <td>Kiel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Land   Textkennzeichen           ARS  \\\n",
       "7   Schleswig-Holstein               NaN            01   \n",
       "8   Schleswig-Holstein  Kreisfreie Stadt         01001   \n",
       "9   Schleswig-Holstein  Kreisfreie Stadt  010010000000   \n",
       "10  Schleswig-Holstein  Kreisfreie Stadt         01002   \n",
       "11  Schleswig-Holstein  Kreisfreie Stadt  010020000000   \n",
       "\n",
       "   Amtlicher Gemeindeschlüssel(AGS)          Gemeinde/Stadt    PLZ        Ort  \n",
       "7                               NaN      Schleswig-Holstein  24105       Kiel  \n",
       "8                               NaN        Flensburg, Stadt  24931  Flensburg  \n",
       "9                          01001000        Flensburg, Stadt  24937  Flensburg  \n",
       "10                              NaN  Kiel, Landeshauptstadt  24103       Kiel  \n",
       "11                         01002000  Kiel, Landeshauptstadt  24103       Kiel  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 7  # Die ersten 7 Zeilen entfernen (keine echten Daten enthalten)\n",
    "df_RS = df_RS.iloc[x:]\n",
    "df_RS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2dfd0",
   "metadata": {},
   "source": [
    "Das Ergebnis ist eine Tabelle mit dem Regionalschlüssel, sowie PLZ und Ort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed053f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export als CSV\n",
    "df_RS.to_csv(f\"{support_data_path}plz_ars.csv\",sep=',',index=False,header=True,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb432532",
   "metadata": {},
   "source": [
    "### Schleife Join ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f394097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearbeite: Regionaltabelle_Bevoelkerung_CSV.csv\n",
      "→ Fertig: Regionaltabelle_Bevoelkerung_CSV_mitPLZ.csv\n",
      "Bearbeite: Regionaltabelle_Bevoelkerung_CSV_mitPLZ.csv\n",
      "→ Fertig: Regionaltabelle_Bevoelkerung_CSV_mitPLZ_mitPLZ.csv\n",
      "Bearbeite: Regionaltabelle_Bildung_Erwerbstaetigkeit_CSV.csv\n",
      "→ Fertig: Regionaltabelle_Bildung_Erwerbstaetigkeit_CSV_mitPLZ.csv\n",
      "Bearbeite: Regionaltabelle_Bildung_Erwerbstaetigkeit_CSV_mitPLZ.csv\n",
      "→ Fertig: Regionaltabelle_Bildung_Erwerbstaetigkeit_CSV_mitPLZ_mitPLZ.csv\n",
      "Bearbeite: Regionaltabelle_Demografie_CSV.csv\n",
      "→ Fertig: Regionaltabelle_Demografie_CSV_mitPLZ.csv\n",
      "Bearbeite: Regionaltabelle_Demografie_CSV_mitPLZ.csv\n",
      "→ Fertig: Regionaltabelle_Demografie_CSV_mitPLZ_mitPLZ.csv\n",
      "Bearbeite: Regionaltabelle_Gebaeude_Wohnungen_CSV.csv\n",
      "→ Fertig: Regionaltabelle_Gebaeude_Wohnungen_CSV_mitPLZ.csv\n",
      "Bearbeite: Regionaltabelle_Gebaeude_Wohnungen_CSV_mitPLZ.csv\n",
      "→ Fertig: Regionaltabelle_Gebaeude_Wohnungen_CSV_mitPLZ_mitPLZ.csv\n",
      "Bearbeite: Regionaltabelle_Haushalte_CSV.csv\n",
      "→ Fertig: Regionaltabelle_Haushalte_CSV_mitPLZ.csv\n",
      "Bearbeite: Regionaltabelle_Haushalte_CSV_mitPLZ.csv\n",
      "→ Fertig: Regionaltabelle_Haushalte_CSV_mitPLZ_mitPLZ.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df_RS = pd.read_csv(support_data_path + \"plz_ars.csv\", dtype={'ARS': str, 'PLZ': str})\n",
    "df_RS['ARS'] = df_RS['ARS'].astype(str).str.zfill(12)\n",
    "\n",
    "# Alle CSV-Dateien im Ordner durchgehen (liefert eine Liste von Strings)\n",
    "for csvfile in glob.glob(zensus_csv_data_path + '*.csv'):\n",
    "    print(f\"Bearbeite: {os.path.basename(csvfile)}\")\n",
    "\n",
    "    df = pd.read_csv(csvfile, dtype={'_RS': str})\n",
    "    df['_RS'] = df['_RS'].astype(str).str.zfill(12)\n",
    "    df_merged = df.merge(df_RS[['ARS', 'PLZ', 'Ort']], left_on='_RS', right_on='ARS', how='left')\n",
    "    df_merged = df_merged.drop(columns=['ARS'])\n",
    "\n",
    "    # Suffix \"_mitPLZ.csv\" anhängen\n",
    "    outname = csvfile.replace('.csv', '_mitPLZ.csv')\n",
    "    df_merged.to_csv(outname, index=False, encoding='utf-8')\n",
    "\n",
    "    print(f\"→ Fertig: {os.path.basename(outname)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb46452",
   "metadata": {},
   "source": [
    "### Sprechende Bezeichnungen für Zensus ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb0d51",
   "metadata": {},
   "source": [
    "#### Säubern der Mapping Dateien ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d078ad8d",
   "metadata": {},
   "source": [
    "Die Mapping-Tabellen bspw. `Regionaltabelle_Bevoelkerung_Mapping.csv` wurden aus den jeweiligen xlsx gezogen. Dort gibt es Sheets namens \"Erläuterung zu CSV-Tabellen\" diese wurden händisch extrahiert und in die Regionaltabelle_XXX_Mapping.csv geschrieben. Diese werden zunächst gesäubert, da dort noch irrelevante Sonderzeichen enthalten sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d21c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bereinigt: ./Datasets/Zensus/Mapping/Regionaltabelle_Bevoelkerung_Mapping_clean.csv\n",
      "Bereinigt: ./Datasets/Zensus/Mapping/Regionaltabelle_Bildung_Erwerbstaetigkeit_Mapping_clean.csv\n",
      "Bereinigt: ./Datasets/Zensus/Mapping/Regionaltabelle_Demografie_Mapping_clean.csv\n",
      "Bereinigt: ./Datasets/Zensus/Mapping/Regionaltabelle_Gebaeude_Wohnungen_Mapping_clean.csv\n",
      "Bereinigt: ./Datasets/Zensus/Mapping/Regionaltabelle_Haushalte_Mapping_clean.csv\n",
      "Alle Mapping-Tabellen wurden gesäubert.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Mapping-Ordner\n",
    "map_ordner = \"./Datasets/Zensus/Mapping/\"\n",
    "\n",
    "# Finde alle Mapping-Tabellen\n",
    "mapping_files = [f for f in os.listdir(map_ordner) if f.endswith('_Mapping.csv')]\n",
    "\n",
    "for fname in mapping_files:\n",
    "    full_in = os.path.join(map_ordner, fname)\n",
    "    full_out = os.path.join(map_ordner, fname.replace('.csv', '_clean.csv'))\n",
    "    \n",
    "    with open(full_in, encoding='utf-8') as fin, open(full_out, 'w', encoding='utf-8') as fout:\n",
    "        for line in fin:\n",
    "            # Entfernt „– “ am Zeilenanfang (Unicode-Gedankenstrich + Leerzeichen)\n",
    "            cleaned = re.sub(r'^[–-]\\s+', '', line)\n",
    "            fout.write(cleaned)\n",
    "    print(f\"Bereinigt: {full_out}\")\n",
    "\n",
    "print(\"Alle Mapping-Tabellen wurden gesäubert.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff8644",
   "metadata": {},
   "source": [
    "Hier findet das eigentliche Mapping statt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdfe1141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei geschrieben: ./Datasets/Zensus/Regionaltabellen/Regionaltabelle_Bevoelkerung_CSV_mitPLZ_final.csv\n",
      "Datei geschrieben: ./Datasets/Zensus/Regionaltabellen/Regionaltabelle_Bildung_Erwerbstaetigkeit_CSV_mitPLZ_final.csv\n",
      "Datei geschrieben: ./Datasets/Zensus/Regionaltabellen/Regionaltabelle_Demografie_CSV_mitPLZ_final.csv\n",
      "Datei geschrieben: ./Datasets/Zensus/Regionaltabellen/Regionaltabelle_Gebaeude_Wohnungen_CSV_mitPLZ_final.csv\n",
      "Datei geschrieben: ./Datasets/Zensus/Regionaltabellen/Regionaltabelle_Haushalte_CSV_mitPLZ_final.csv\n",
      "Alle Tabellen wurden verarbeitet.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ordner mit den Regionaltabellen\n",
    "datapath_regionaltabellen = zensus_csv_data_path\n",
    "\n",
    "# Mapping-Ordner (bitte den Pfad passend zu deiner Struktur)\n",
    "mapping_folder = map_ordner\n",
    "\n",
    "output_path_csv = \"./Datasets/Zensus/Regionaltabellen/\"\n",
    "\n",
    "# Hole alle relevanten CSV-Dateien\n",
    "regional_csvs = [f for f in os.listdir(datapath_regionaltabellen) if f.endswith(\"_CSV_mitPLZ.csv\")]\n",
    "\n",
    "for csv_file in regional_csvs:\n",
    "    base_name = csv_file.replace(\"_CSV_mitPLZ.csv\", \"\")\n",
    "    mapping_file = f\"{base_name}_Mapping_clean.csv\"\n",
    "    csv_path = os.path.join(datapath_regionaltabellen, csv_file)\n",
    "    mapping_path = os.path.join(mapping_folder, mapping_file)\n",
    "\n",
    "    if not os.path.exists(mapping_path):\n",
    "        print(f\"Mapping nicht gefunden für: {csv_file}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(csv_path, dtype=str)\n",
    "\n",
    "    # Mapping laden: Zwei Spalten, erste Zeile überspringen, eigene Spaltennamen\n",
    "    mapping = pd.read_csv(mapping_path, dtype=str, header=None, skiprows=1, names=[\"alt\", \"neu\"])\n",
    "\n",
    "    # Optionale Filter: nur Zeilen mit echten Werten und keine Kommentare\n",
    "    mapping = mapping[mapping[\"alt\"].notnull() & mapping[\"neu\"].notnull()]\n",
    "    mapping = mapping[~mapping[\"alt\"].str.startswith(\"–\")]\n",
    "\n",
    "    # Mapping-Dictionary bauen\n",
    "    col_map = dict(zip(mapping[\"alt\"], mapping[\"neu\"]))\n",
    "\n",
    "    # Spalten umbenennen (Berichtszeitpunkt bleibt, alles andere wird gemappt)\n",
    "    new_columns = [col if col == \"Berichtszeitpunkt\" else col_map.get(col, col) for col in df.columns]\n",
    "    df.columns = new_columns\n",
    "\n",
    "    # Datei speichern\n",
    "    output_path = os.path.join(output_path_csv, f\"{base_name}_CSV_mitPLZ_final.csv\")\n",
    "    df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"Datei geschrieben: {output_path}\")\n",
    "\n",
    "print(\"Alle Tabellen wurden verarbeitet.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
